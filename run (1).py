import os
import uuid
import base64
import subprocess
import requests
import streamlit as st
from pydub import AudioSegment
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
import soundfile as sf
import numpy as np


st.set_page_config(page_title="Story Generator (LLM + TTS + Video)", page_icon="ğŸ§", layout="centered")


LLM_API_KEY = 
TTS_API_KEY = 


def ensure_ffmpeg_installed():
    try:
        subprocess.run(["ffmpeg", "-version"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    except FileNotFoundError:
        st.error("âŒ ffmpeg ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø¨Ø±Ø¬Ø§Ø¡ ØªØ«Ø¨ÙŠØªÙ‡ ÙÙŠ Ø§Ù„Ø¨ÙŠØ¦Ø© Ù‚Ø¨Ù„ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.")

# ======================================
# ğŸ§  Node 1 â€” Generate Story (Arabic + 2 mins)
# ======================================
def node_generate_story(prompt: str) -> str:
    prompt_with_limit = (
        "Ø§ÙƒØªØ¨ Ø§Ù„Ù‚ØµØ© Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ© ÙÙ‚Ø·ØŒ ÙˆØ§Ø¬Ø¹Ù„Ù‡Ø§ Ù…ÙƒØªÙˆØ¨Ø© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ "
        "Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø´ÙŠÙ‚ ÙˆÙ…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø£Ø·ÙØ§Ù„ØŒ Ù…Ø¹ Ø­Ø¨ÙƒØ© Ù‚ØµÙŠØ±Ø© ÙˆÙ…Ù…ØªØ¹Ø©ØŒ "
        "ÙˆÙ„Ø§ ØªØªØ¬Ø§ÙˆØ² Ù…Ø¯Ø© Ø±ÙˆØ§ÙŠØªÙ‡Ø§ Ø¯Ù‚ÙŠÙ‚ØªÙŠÙ† Ø¹Ù†Ø¯Ù…Ø§ ØªÙØ±ÙˆÙ‰ Ø¨ØµÙˆØª Ø·Ø¨ÙŠØ¹ÙŠ. "
        "Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù‚ØµØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©: " + prompt
    )

    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        google_api_key=LLM_API_KEY,
        temperature=0.7
    )

    response = llm.invoke([HumanMessage(content=prompt_with_limit)])
    content = getattr(response, "content", response)

    if isinstance(content, list):
        if len(content) > 0:
            if isinstance(content[0], dict) and "text" in content[0]:
                story = content[0]["text"]
            else:
                story = content[0]
        else:
            story = ""
    else:
        story = content

    return str(story).strip()

# ======================================
# ğŸ”Š Node 2 â€” Text to Speech (Arabic + Egyptian)
# ======================================
def node_text_to_speech(story_text: str):
    MODEL = "models/gemini-2.5-pro-preview-tts"
    URL = f"https://generativelanguage.googleapis.com/v1beta/{MODEL}:generateContent?key={TTS_API_KEY}"

    style_instruction = (
        "Ø§ØªÙƒÙ„Ù… Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©ØŒ Ø¨ØµÙˆØª ÙˆØ§Ø¶Ø­ ÙˆÙ…Ù„ÙŠØ§Ù† Ø­ÙŠÙˆÙŠØ© ÙƒØ£Ù†Ùƒ Ø¨ØªØ­ÙƒÙŠ Ù„Ù„Ø£Ø·ÙØ§Ù„ Ù‚ØµØ© Ù…Ù…ØªØ¹Ø©. "
        "Ø®Ù„ÙŠ Ø§Ù„Ù†Ø·Ù‚ Ù…ØµØ±ÙŠ Ø£ØµÙŠÙ„ (Ø¬ = gØŒ Ù‚ = â€™a) ÙˆØ§Ù„Ù†Ø¨Ø±Ø© ÙÙŠÙ‡Ø§ Ø¯ÙØ¡ ÙˆØ¶Ø­Ùƒ Ø¨Ø³ÙŠØ·ØŒ "
        "Ø²ÙŠ Ø§Ù„Ø±Ø§ÙˆÙŠ ÙÙŠ ÙƒØ±ØªÙˆÙ† Ù…ØµØ±ÙŠ Ø¨ÙŠØ­ÙƒÙŠ Ù„Ù„Ø£Ø·ÙØ§Ù„ Ø¨Ø­Ù…Ø§Ø³ ÙˆÙˆØ¯. "
        "Ø®Ù„ÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙŠÙƒÙˆÙ† ÙÙŠÙ‡ Ù…Ø´Ø§Ø¹Ø± Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙˆØ¯ÙØ¡ØŒ ÙˆØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ù…ØµØ±ÙŠ Ø§Ù„Ù…Ù…Ø²ÙˆØ¬ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ø®ÙÙŠÙØ©.\n\n"
    )

    payload = {
        "contents": [{"role": "user", "parts": [{"text": style_instruction + story_text}]}],
        "generationConfig": {
            "response_modalities": ["AUDIO"],
            "speech_config": {"voiceConfig": {"prebuiltVoiceConfig": {"voiceName": "Leda"}}}
        }
    }

    headers = {"Content-Type": "application/json"}
    response = requests.post(URL, headers=headers, json=payload)

    if response.status_code != 200:
        st.error(f"âŒ Ø®Ø·Ø£ {response.status_code}: {response.text}")
        return None, None

    result = response.json()
    try:
        audio_base64 = result["candidates"][0]["content"]["parts"][0]["inlineData"]["data"]
    except KeyError:
        st.error("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØª ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©.")
        return None, None

    raw_bytes = base64.b64decode(audio_base64)
    audio_np = np.frombuffer(raw_bytes, dtype=np.int16)
    wav_path = os.path.abspath(f"story_audio_{uuid.uuid4().hex[:6]}.wav")
    sf.write(wav_path, audio_np, samplerate=24000, subtype="PCM_16")

    # Normalize & fix frame rate
    audio = AudioSegment.from_wav(wav_path).set_frame_rate(24000)
    audio.export(wav_path, format="wav")

    with open(wav_path, "rb") as f:
        wav_bytes = f.read()

    return wav_path, wav_bytes

# ======================================
# ğŸ¬ Node 3 â€” LatentSync Video Generation
# ======================================
def node_generate_video(audio_path: str):
    st.info("ğŸ¬ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Latent Sync...")

    try:
        cwd = os.getcwd()
        latentsync_dir = "/teamspace/studios/this_studio/LatentSync"
        os.chdir(latentsync_dir)

        base_video_path = os.path.join(latentsync_dir, "cartoongda.mp4")
        output_name = f"cartoon_output_{uuid.uuid4().hex[:6]}.mp4"
        output_path = os.path.join(latentsync_dir, output_name)

        if not os.path.exists(base_video_path):
            st.error("âŒ Ù…Ù„Ù Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ cartoon4women.mp4 ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
            os.chdir(cwd)
            return None

        command = [
            "python", "-m", "scripts.inference",
            "--unet_config_path", "configs/unet/stage2_512.yaml",
            "--inference_ckpt_path", "checkpoints/latentsync_unet.pt",
            "--inference_steps", "25",
            "--guidance_scale", "2.0",
            "--video_path", base_video_path,
            "--audio_path", audio_path,
            "--video_out_path", output_path
        ]

        result = subprocess.run(command, capture_output=True, text=True)
        os.chdir(cwd)

        if result.returncode == 0 and os.path.exists(output_path):
            return output_path
        else:
            st.error("âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ.")
            st.text(result.stderr)
            return None

    except Exception as e:
        st.error(f"âš ï¸ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {e}")
        return None

# ======================================
# ğŸš€ STREAMLIT APP (with session_state)
# ======================================
st.title("ğŸ™ï¸ Ù…ÙÙ†Ø´Ø¦ Ø§Ù„Ù‚ØµØµ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ© Ø¨Ø§Ù„ØµÙˆØª ÙˆØ§Ù„ÙÙŠØ¯ÙŠÙˆ ğŸ¬")

ensure_ffmpeg_installed()

# Initialize session state
for key in ["story", "audio_path", "audio_bytes", "video_path"]:
    if key not in st.session_state:
        st.session_state[key] = None

prompt = st.text_area("âœï¸ Ø§ÙƒØªØ¨ ÙÙƒØ±Ø© Ø§Ù„Ù‚ØµØ©:", "Ø§ÙƒØªØ¨ Ù„ÙŠ Ù‚ØµØ© Ù‚ØµÙŠØ±Ø© Ø¹Ù† ÙØªØ§Ø© Ø´Ø¬Ø§Ø¹Ø© ØªØ¹ÙŠØ´ ÙÙŠ Ø§Ù„ØµØ­Ø±Ø§Ø¡ ÙˆØªÙƒØªØ´Ù ÙƒÙ†Ø²Ù‹Ø§ Ø³Ø­Ø±ÙŠÙ‹Ø§.")

if st.button("ğŸš€ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù‚ØµØ© + Ø§Ù„ØµÙˆØª + Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"):
    # ğŸ§  Generate Story
    with st.spinner("ğŸ§  Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù‚ØµØ©..."):
        st.session_state.story = node_generate_story(prompt)
        st.subheader("ğŸ“– Ø§Ù„Ù‚ØµØ© Ø§Ù„Ù†Ø§ØªØ¬Ø©")
        st.write(st.session_state.story)

    # ğŸ”Š Generate Audio
    with st.spinner("ğŸ¤ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØª..."):
        st.session_state.audio_path, st.session_state.audio_bytes = node_text_to_speech(st.session_state.story)
        if st.session_state.audio_bytes:
            st.success("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØª Ø¨Ù†Ø¬Ø§Ø­.")
            st.audio(st.session_state.audio_bytes, format="audio/wav")

    # ğŸ¬ Generate Video
    if st.session_state.audio_path:
        with st.spinner("ğŸï¸ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ..."):
            st.session_state.video_path = node_generate_video(st.session_state.audio_path)
            if st.session_state.video_path:
                st.video(st.session_state.video_path)
                st.success("ğŸ¬ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ù†Ø¬Ø§Ø­!")

# âœ… Display saved state even after rerun
if st.session_state.story:
    st.subheader("ğŸ“– Ø§Ù„Ù‚ØµØ©:")
    st.write(st.session_state.story)

if st.session_state.audio_bytes:
    st.subheader("ğŸ§ Ø§Ù„ØµÙˆØª:")
    st.audio(st.session_state.audio_bytes, format="audio/wav")
    st.download_button(
        "â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª",
        data=st.session_state.audio_bytes,
        file_name=os.path.basename(st.session_state.audio_path),
        mime="audio/wav"
    )

if st.session_state.video_path and os.path.exists(st.session_state.video_path):
    st.subheader("ğŸ¬ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ:")
    st.video(st.session_state.video_path)
